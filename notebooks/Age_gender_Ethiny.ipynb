{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242b96d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 13:37:26.861739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-09 13:37:26.861809: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "import joblib\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75beb52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219203650636.jpg.chip.jpg</td>\n",
       "      <td>[129.0, 128.0, 128.0, 126.0, 127.0, 130.0, 133...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222752047.jpg.chip.jpg</td>\n",
       "      <td>[164.0, 74.0, 111.0, 168.0, 169.0, 171.0, 175....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222832191.jpg.chip.jpg</td>\n",
       "      <td>[67.0, 70.0, 71.0, 70.0, 69.0, 67.0, 70.0, 79....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144911423.jpg.chip.jpg</td>\n",
       "      <td>[193.0, 197.0, 198.0, 200.0, 199.0, 200.0, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144914327.jpg.chip.jpg</td>\n",
       "      <td>[202.0, 205.0, 209.0, 210.0, 209.0, 209.0, 210...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  ethnicity  gender                        img_name  \\\n",
       "0    1          2       0  20161219203650636.jpg.chip.jpg   \n",
       "1    1          2       0  20161219222752047.jpg.chip.jpg   \n",
       "2    1          2       0  20161219222832191.jpg.chip.jpg   \n",
       "3    1          2       0  20161220144911423.jpg.chip.jpg   \n",
       "4    1          2       0  20161220144914327.jpg.chip.jpg   \n",
       "\n",
       "                                              pixels  \n",
       "0  [129.0, 128.0, 128.0, 126.0, 127.0, 130.0, 133...  \n",
       "1  [164.0, 74.0, 111.0, 168.0, 169.0, 171.0, 175....  \n",
       "2  [67.0, 70.0, 71.0, 70.0, 69.0, 67.0, 70.0, 79....  \n",
       "3  [193.0, 197.0, 198.0, 200.0, 199.0, 200.0, 202...  \n",
       "4  [202.0, 205.0, 209.0, 210.0, 209.0, 209.0, 210...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../raw_data/age_gender.csv')\n",
    "\n",
    "## Converting pixels into numpy array\n",
    "data['pixels']=data['pixels'].apply(lambda x:  np.array(x.split(), dtype=\"float32\"))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0910104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 23705\n",
      "Total columns: 5\n"
     ]
    }
   ],
   "source": [
    "print('Total rows: {}'.format(len(data)))\n",
    "print('Total columns: {}'.format(len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b1427d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalizing pixels data\n",
    "data['pixels'] = data['pixels'].apply(lambda x: x/255)\n",
    "\n",
    "## calculating distributions\n",
    "age_dist = data['age'].value_counts()\n",
    "ethnicity_dist = data['ethnicity'].value_counts()\n",
    "gender_dist = data['gender'].value_counts().rename(index={0:'Male',1:'Female'})\n",
    "\n",
    "def ditribution_plot(x,y,name):\n",
    "    fig = go.Figure([\n",
    "        go.Bar(x=x, y=y)\n",
    "    ])\n",
    "\n",
    "    fig.update_layout(title_text=name)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "ditribution_plot(x=age_dist.index, y=age_dist.values, name='Age Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd782b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ditribution_plot(x=ethnicity_dist.index, y=ethnicity_dist.values, name='Ethnicity Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e44405",
   "metadata": {},
   "outputs": [],
   "source": [
    "ditribution_plot(x=gender_dist.index, y=gender_dist.values, name='Gender Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98cf2a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data['pixels'].tolist())\n",
    "\n",
    "## Converting pixels from 1D to 3D\n",
    "X = X.reshape(X.shape[0],48,48,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64461deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "for i in range(1480,1500):\n",
    "    plt.subplot(5,5,(i%25)+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(data['pixels'].iloc[i].reshape(48,48))\n",
    "    plt.xlabel(\n",
    "        \"Age:\"+str(data['age'].iloc[i])+\n",
    "        \"  Ethnicity:\"+str(data['ethnicity'].iloc[i])+\n",
    "        \"  Gender:\"+ str(data['gender'].iloc[i])\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47bbb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gender = np.array(data['gender'])\n",
    "\n",
    "X_train_gender, X_test_gender, y_train_gender, y_test_gender = train_test_split(\n",
    "    X, y_gender, test_size=0.22, random_state=37\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b14d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 13:37:49.723459: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-09 13:37:49.723534: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-09 13:37:49.723569: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-BKG5TOC): /proc/driver/nvidia/version does not exist\n",
      "2022-04-09 13:37:49.723846: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel_gender.compile(optimizer=\\'sgd\\',\\n              loss=tf.keras.losses.BinaryCrossentropy(),\\n              metrics=[\\'accuracy\\'])\\n\\n\\n## Stop training when validation loss reach 0.2700\\nclass myCallback(tf.keras.callbacks.Callback):\\n    def on_epoch_end(self, epoch, logs={}):\\n        if(logs.get(\\'val_loss\\')<0.2900):\\n            print(\"\\nReached 0.2900 val_loss so cancelling training!\")\\n            self.model.stop_training = True\\n        \\ncallback = myCallback()\\n\\nmodel_gender.summary()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model_gender = tf.keras.Sequential([\n",
    "    L.InputLayer(input_shape=(48,48,1)),\n",
    "    L.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Conv2D(64, (3, 3), activation='relu'),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Flatten(),\n",
    "    L.Dense(64, activation='relu'),\n",
    "    L.Dropout(rate=0.5),\n",
    "    L.Dense(1, activation='sigmoid')\n",
    "])\n",
    "'''\n",
    "def initialize_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), input_shape=(48, 48, 1), activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2))) \n",
    "    model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(rate=0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "model_gender = initialize_model()\n",
    "\n",
    "'''\n",
    "model_gender.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "## Stop training when validation loss reach 0.2700\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_loss')<0.2900):\n",
    "            print(\"\\nReached 0.2900 val_loss so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "        \n",
    "callback = myCallback()\n",
    "\n",
    "model_gender.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df49914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model_gender.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=3,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "model_gender.compile(loss='binary_crossentropy',\n",
    "              optimizer = 'sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_gender = model_gender.fit(\n",
    "    X_train_gender, y_train_gender, epochs=40, validation_split=0.1, batch_size=64, callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37136432",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model_gender, 'model_gender.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gender.save('model_gender.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87857bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    history_gender.history, y=['loss', 'val_loss'],\n",
    "    labels={'index': 'epoch', 'value': 'loss'}, \n",
    "    title='Training History')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6201be",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model_gender.evaluate(X_test_gender,y_test_gender,verbose=0)\n",
    "print('Test loss: {}'.format(loss))\n",
    "print('Test Accuracy: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07af7100",
   "metadata": {},
   "source": [
    "Ethiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e83e873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "y_ethiny = data['ethnicity']\n",
    "ethnicity = to_categorical(y_ethiny, num_classes = 5)\n",
    "\n",
    "X_train_ethiny, X_test_ethiny, y_train_ethiny, y_test_ethiny = train_test_split(\n",
    "    X, ethnicity, test_size=0.22, random_state=37\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3de752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), input_shape=(48, 48, 1), activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2))) \n",
    "    model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(rate=0.5))\n",
    "    model.add(layers.Dense(5, activation = 'softmax'))\n",
    "    return model\n",
    "\n",
    "model_ethiny = initialize_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ethiny.compile(loss='categorical_crossentropy',\n",
    "              optimizer = 'rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ethiny = model_ethiny.fit(\n",
    "    X_train_ethiny, y_train_ethiny, epochs=20, validation_split=0.1, batch_size=64, callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ethiny.save(\"model_ethiny.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25372d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model_ethiny.evaluate(X_test_ethiny,y_test_ethiny,verbose=0)\n",
    "print('Test loss: {}'.format(loss))\n",
    "print('Test Accuracy: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad9c14",
   "metadata": {},
   "source": [
    "Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c3b35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ages(x):\n",
    "    if x<=2:\n",
    "        return 0\n",
    "    elif x<=12:\n",
    "        return 1\n",
    "    elif x<=18:\n",
    "        return 2\n",
    "    elif x<= 26:\n",
    "        return 3\n",
    "    elif x<= 50:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c17fac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age_new\"] = data[\"age\"].apply(lambda x: ages(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b984237",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cat = to_categorical(data['age_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a4e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_age, X_test_age, y_train_age, y_test_age = train_test_split(\n",
    "    X, age_cat, test_size=0.22, random_state=37\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e378f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), input_shape=(48, 48, 1), activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2))) \n",
    "    model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(rate=0.5))\n",
    "    model.add(layers.Dense(6, activation = 'softmax'))\n",
    "    return model\n",
    "\n",
    "model_age = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9766f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_age.compile(loss='categorical_crossentropy',\n",
    "              optimizer = 'rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "694df0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "260/260 [==============================] - ETA: 0s - loss: 1.3349 - accuracy: 0.4475WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "260/260 [==============================] - 35s 129ms/step - loss: 1.3349 - accuracy: 0.4475 - val_loss: 1.5848 - val_accuracy: 0.4619 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "260/260 [==============================] - ETA: 0s - loss: 1.0859 - accuracy: 0.5379WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "260/260 [==============================] - 33s 128ms/step - loss: 1.0859 - accuracy: 0.5379 - val_loss: 1.1936 - val_accuracy: 0.5635 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "260/260 [==============================] - ETA: 0s - loss: 1.0129 - accuracy: 0.5659WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "260/260 [==============================] - 33s 126ms/step - loss: 1.0129 - accuracy: 0.5659 - val_loss: 1.0739 - val_accuracy: 0.5646 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "260/260 [==============================] - ETA: 0s - loss: 0.9525 - accuracy: 0.5951WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "260/260 [==============================] - 33s 126ms/step - loss: 0.9525 - accuracy: 0.5951 - val_loss: 0.8473 - val_accuracy: 0.6636 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "260/260 [==============================] - ETA: 0s - loss: 0.9114 - accuracy: 0.6096WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "260/260 [==============================] - 33s 128ms/step - loss: 0.9114 - accuracy: 0.6096 - val_loss: 0.8500 - val_accuracy: 0.6387 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "260/260 [==============================] - ETA: 0s - loss: 0.8659 - accuracy: 0.6262WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "260/260 [==============================] - 34s 132ms/step - loss: 0.8659 - accuracy: 0.6262 - val_loss: 1.1016 - val_accuracy: 0.5998 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "260/260 [==============================] - ETA: 0s - loss: 0.8297 - accuracy: 0.6471WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "260/260 [==============================] - 35s 135ms/step - loss: 0.8297 - accuracy: 0.6471 - val_loss: 0.8085 - val_accuracy: 0.6544 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "260/260 [==============================] - ETA: 0s - loss: 0.8068 - accuracy: 0.6486WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "260/260 [==============================] - 36s 137ms/step - loss: 0.8068 - accuracy: 0.6486 - val_loss: 0.9509 - val_accuracy: 0.6376 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "260/260 [==============================] - ETA: 0s - loss: 0.7796 - accuracy: 0.6670WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "260/260 [==============================] - 36s 137ms/step - loss: 0.7796 - accuracy: 0.6670 - val_loss: 0.8426 - val_accuracy: 0.6598 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "260/260 [==============================] - ETA: 0s - loss: 0.7592 - accuracy: 0.6734Restoring model weights from the end of the best epoch: 7.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "260/260 [==============================] - 36s 138ms/step - loss: 0.7592 - accuracy: 0.6734 - val_loss: 1.3362 - val_accuracy: 0.6063 - lr: 0.0010\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_age = model_age.fit(\n",
    "    X_train_age, y_train_age, epochs=20, validation_split=0.1, batch_size=64, callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c191b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_age.save(\"model_age.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ae10d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
